#!/usr/bin/env python3
"""
å¤å¢³æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®æœ€é©åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import torch
import cv2
import numpy as np
import os
import sys
from pathlib import Path
import matplotlib.pyplot as plt
from typing import List, Dict, Tuple

# Replace yolov5 with ultralytics
from ultralytics import YOLO

class KofunDetectionOptimizer:
    def __init__(self, weights_path='weights/best.pt'):
        self.weights_path = weights_path
        # Remove device selection - ultralytics handles this automatically
        self.model = None
        self.load_model()
        
    def load_model(self):
        """ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã¨æœ€é©åŒ–"""
        print("ğŸ”„ Loading and optimizing model...")
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆultralytics YOLOï¼‰
        self.model = YOLO(self.weights_path)
        
        print("âœ… Model loaded successfully")
    
    def optimize_inference_parameters(self, test_image_path: str) -> Dict:
        """æ¨è«–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©åŒ–"""
        print("ğŸ”§ Optimizing inference parameters...")
        
        # ãƒ†ã‚¹ãƒˆç”»åƒã®èª­ã¿è¾¼ã¿
        img = cv2.imread(test_image_path)
        if img is None:
            print(f"âŒ Could not load test image: {test_image_path}")
            return {}
        
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ã‚’ãƒ†ã‚¹ãƒˆ
        conf_thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]
        iou_thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]
        
        best_params = {
            'conf_threshold': 0.3,
            'iou_threshold': 0.5,
            'max_detections': 0,
            'avg_confidence': 0.0
        }
        
        for conf_thresh in conf_thresholds:
            for iou_thresh in iou_thresholds:
                detections = self.run_inference(img, conf_thresh, iou_thresh)
                
                if len(detections) > 0:
                    avg_conf = np.mean([d['confidence'] for d in detections])
                    
                    if avg_conf > best_params['avg_confidence']:
                        best_params = {
                            'conf_threshold': conf_thresh,
                            'iou_threshold': iou_thresh,
                            'max_detections': len(detections),
                            'avg_confidence': avg_conf
                        }
        
        print(f"âœ… Best parameters found: {best_params}")
        return best_params
    
    def run_inference(self, img: np.ndarray, conf_threshold: float = 0.3, 
                     iou_threshold: float = 0.5) -> List[Dict]:
        """æ¨è«–å®Ÿè¡Œ"""
        # æ¨è«–ï¼ˆultralytics YOLOï¼‰
        results = self.model(img, conf=conf_threshold, iou=iou_threshold)
        
        detections = []
        for result in results:
            if result.boxes is not None:
                boxes = result.boxes
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = box.conf[0].cpu().numpy()
                    cls = box.cls[0].cpu().numpy()
                    
                    detections.append({
                        'x_center': (x1 + x2) / 2,
                        'y_center': (y1 + y2) / 2,
                        'width': x2 - x1,
                        'height': y2 - y1,
                        'confidence': conf,
                        'class': int(cls)
                    })
        
        return detections
    
    def apply_ensemble_detection(self, img: np.ndarray, num_models: int = 3) -> List[Dict]:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ¤œå‡ºã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š"""
        print("ğŸ¯ Applying ensemble detection...")
        
        # è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§æ¤œå‡º
        model_sizes = [(640, 640), (512, 512), (768, 768)]
        all_detections = []
        
        for size in model_sizes[:num_models]:
            # ç”»åƒã‚’ãƒªã‚µã‚¤ã‚º
            img_resized = cv2.resize(img, size)
            
            # æ¨è«–ï¼ˆultralytics YOLOï¼‰
            results = self.model(img_resized, conf=0.25, iou=0.45)
            
            for result in results:
                if result.boxes is not None:
                    boxes = result.boxes
                    for box in boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        conf = box.conf[0].cpu().numpy()
                        cls = box.cls[0].cpu().numpy()
                        
                        # å…ƒã®ç”»åƒã‚µã‚¤ã‚ºã«ã‚¹ã‚±ãƒ¼ãƒ«ãƒãƒƒã‚¯
                        scale_x = img.shape[1] / size[0]
                        scale_y = img.shape[0] / size[1]
                        
                        all_detections.append({
                            'x_center': (x1 + x2) / 2 * scale_x,
                            'y_center': (y1 + y2) / 2 * scale_y,
                            'width': (x2 - x1) * scale_x,
                            'height': (y2 - y1) * scale_y,
                            'confidence': conf,
                            'class': int(cls)
                        })
        
        # é‡è¤‡æ¤œå‡ºã®çµ±åˆ
        merged_detections = self.merge_ensemble_detections(all_detections)
        return merged_detections
    
    def merge_ensemble_detections(self, detections: List[Dict], iou_threshold: float = 0.5) -> List[Dict]:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ¤œå‡ºçµæœã®çµ±åˆ"""
        if not detections:
            return []
        
        # ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆ
        detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)
        merged = []
        
        for det in detections:
            is_duplicate = False
            for existing in merged:
                iou = self.calculate_iou(det, existing)
                if iou > iou_threshold:
                    # é‡è¤‡ã®å ´åˆã€ä¿¡é ¼åº¦ã®é«˜ã„æ–¹ã‚’ä¿æŒ
                    if det['confidence'] > existing['confidence']:
                        merged.remove(existing)
                        merged.append(det)
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                merged.append(det)
        
        return merged
    
    def calculate_iou(self, det1: Dict, det2: Dict) -> float:
        """IoUè¨ˆç®—"""
        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’è¨ˆç®—
        def det_to_bbox(det):
            x1 = det['x_center'] - det['width'] / 2
            y1 = det['y_center'] - det['height'] / 2
            x2 = det['x_center'] + det['width'] / 2
            y2 = det['y_center'] + det['height'] / 2
            return x1, y1, x2, y2
        
        bbox1 = det_to_bbox(det1)
        bbox2 = det_to_bbox(det2)
        
        # äº¤å·®éƒ¨åˆ†ã‚’è¨ˆç®—
        x1 = max(bbox1[0], bbox2[0])
        y1 = max(bbox1[1], bbox2[1])
        x2 = min(bbox1[2], bbox2[2])
        y2 = min(bbox1[3], bbox2[3])
        
        if x2 <= x1 or y2 <= y1:
            return 0.0
        
        intersection = (x2 - x1) * (y2 - y1)
        area1 = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])
        area2 = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def create_optimized_model_config(self) -> Dict:
        """æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ä½œæˆ"""
        return {
            'ensemble_enabled': True,
            'num_ensemble_models': 3,
            'conf_threshold': 0.25,
            'iou_threshold': 0.45,
            'max_detections': 100,
            'post_processing': {
                'merge_overlapping': True,
                'confidence_boost': True,
                'size_filtering': True
            }
        }
    
    def save_optimization_results(self, results: Dict, output_path: str = 'optimization_results.json'):
        """æœ€é©åŒ–çµæœã®ä¿å­˜"""
        import json
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"âœ… Optimization results saved to {output_path}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ Starting Kofun Detection Model Optimization...")
    
    # æœ€é©åŒ–å™¨ã®åˆæœŸåŒ–
    optimizer = KofunDetectionOptimizer()
    
    # ãƒ†ã‚¹ãƒˆç”»åƒã®ãƒ‘ã‚¹ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
    test_image_path = 'static/results/converted.png'
    
    if os.path.exists(test_image_path):
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
        best_params = optimizer.optimize_inference_parameters(test_image_path)
        
        # æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®šã‚’ä½œæˆ
        optimized_config = optimizer.create_optimized_model_config()
        optimized_config.update(best_params)
        
        # çµæœã‚’ä¿å­˜
        optimizer.save_optimization_results(optimized_config)
        
        print("ğŸ‰ Model optimization completed!")
        print(f"ğŸ“Š Optimized parameters: {optimized_config}")
    else:
        print(f"âš ï¸ Test image not found: {test_image_path}")
        print("ğŸ’¡ Please run inference first to generate test images")

if __name__ == "__main__":
    main() 