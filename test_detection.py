#!/usr/bin/env python3
"""
å¤å¢³æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys
sys.path.insert(0, os.path.abspath('yolov5'))

from xml_to_png import convert_xml_to_png
from my_utils import parse_latlon_range, bbox_to_latlon, read_yolo_labels
import torch
import cv2
import numpy as np
from pathlib import Path

def test_detection(xml_file_path):
    """
    æŒ‡å®šã•ã‚ŒãŸXMLãƒ•ã‚¡ã‚¤ãƒ«ã§æ¨è«–ã‚’ãƒ†ã‚¹ãƒˆ
    """
    print(f"ğŸ” Testing detection with: {xml_file_path}")
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æº–å‚™
    output_dir = "test_results"
    os.makedirs(output_dir, exist_ok=True)
    
    # XML â†’ PNG å¤‰æ›
    png_path = os.path.join(output_dir, "test_converted.png")
    print("ğŸ“Š Converting XML to PNG...")
    convert_xml_to_png(xml_file_path, png_path)
    
    # YOLOv5 æ¨è«–å®Ÿè¡Œï¼ˆç°¡ç´ åŒ–ç‰ˆï¼‰
    print("ğŸ¤– Running YOLOv5 inference...")
    try:
        # ãƒ¢ãƒ‡ãƒ«ã‚’ç›´æ¥èª­ã¿è¾¼ã¿
        model_path = 'yolov5/weights/best.pt'
        if not os.path.exists(model_path):
            print(f"âŒ Model not found: {model_path}")
            return
        
        # ç”»åƒèª­ã¿è¾¼ã¿
        image = cv2.imread(png_path)
        if image is None:
            print(f"âŒ Could not read image: {png_path}")
            return
        
        # ç”»åƒã‚µã‚¤ã‚ºèª¿æ•´
        img_size = 640
        img = cv2.resize(image, (img_size, img_size))
        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
        img = np.ascontiguousarray(img)
        img = torch.from_numpy(img).float()
        img /= 255.0
        if len(img.shape) == 3:
            img = img[None]
        
        # æ¨è«–å®Ÿè¡Œï¼ˆCPUä½¿ç”¨ï¼‰
        device = torch.device('cpu')
        img = img.to(device)
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã¨æ¨è«–ï¼ˆPyTorch 2.6å¯¾å¿œï¼‰
        model = torch.load(model_path, map_location=device, weights_only=False)
        if 'model' in model:
            model = model['model']
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’float32ã«å¤‰æ›
        model = model.float()
        model.eval()
        
        with torch.no_grad():
            pred = model(img)
        
        # çµæœå‡¦ç†
        conf_threshold = 0.1
        detections = []
        
        if len(pred) > 0:
            pred = pred[0]  # æœ€åˆã®ç”»åƒã®çµæœ
            print(f"æ¨è«–çµæœã®å½¢çŠ¶: {pred.shape}")
            
            # çµæœã‚’é©åˆ‡ã«å‡¦ç†
            for i in range(pred.shape[0]):
                detection = pred[i]  # 25200å€‹ã®æ¤œå‡ºçµæœ
                
                # å„æ¤œå‡ºçµæœã‚’å‡¦ç†
                for j in range(detection.shape[0]):
                    single_detection = detection[j]
                    x1 = single_detection[0].item()
                    y1 = single_detection[1].item()
                    x2 = single_detection[2].item()
                    y2 = single_detection[3].item()
                    conf = single_detection[4].item()
                    cls = single_detection[5].item()
                    
                    if conf > conf_threshold:
                        # YOLOåº§æ¨™ã‚’ä¸­å¿ƒåº§æ¨™ã«å¤‰æ›
                        x_center = (x1 + x2) / 2 / img_size
                        y_center = (y1 + y2) / 2 / img_size
                        width = (x2 - x1) / img_size
                        height = (y2 - y1) / img_size
                        
                        detections.append({
                            'x_center': x_center,
                            'y_center': y_center,
                            'width': width,
                            'height': height,
                            'confidence': conf,
                            'class': cls
                        })
        
        print(f"ğŸ¯ Found {len(detections)} detection(s)")
        
        # çµæœã®è§£æ
        print("ğŸ“ˆ Analyzing results...")
        try:
            # åº§æ¨™ç¯„å›²ã‚’å–å¾—
            lat0, lon0, lat1, lon1 = parse_latlon_range(xml_file_path)
            print(f"ğŸ“ Coordinate range: Lat {lat0:.6f}-{lat1:.6f}, Lon {lon0:.6f}-{lon1:.6f}")
            
            if detections:
                print("âœ… KOFUN DETECTED!")
                for i, detection in enumerate(detections):
                    lat, lon = bbox_to_latlon(detection, lat0, lon0, lat1, lon1)
                    conf = detection.get('confidence', 0.0)
                    print(f"   Detection #{i+1}: Lat {lat:.6f}, Lon {lon:.6f}, Confidence {conf:.3f}")
            else:
                print("âŒ No kofun detected")
                
        except Exception as e:
            print(f"âŒ Error analyzing results: {e}")
        
        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        result_file = os.path.join(output_dir, "detection_results.txt")
        with open(result_file, 'w') as f:
            f.write(f"Detection Results for {xml_file_path}\n")
            f.write(f"Total detections: {len(detections)}\n")
            for i, detection in enumerate(detections):
                lat, lon = bbox_to_latlon(detection, lat0, lon0, lat1, lon1)
                conf = detection.get('confidence', 0.0)
                f.write(f"Detection #{i+1}: Lat {lat:.6f}, Lon {lon:.6f}, Confidence {conf:.3f}\n")
        
        print(f"ğŸ“ Results saved to: {result_file}")
        
    except Exception as e:
        print(f"âŒ Error during inference: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨XMLãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ï¼‰
    test_xml = "uploads/FG-GML-4930-64-23-DEM5A-20250620.xml"
    
    if os.path.exists(test_xml):
        test_detection(test_xml)
    else:
        print(f"âŒ Test XML file not found: {test_xml}")
        print("Available XML files:")
        uploads_dir = "uploads"
        if os.path.exists(uploads_dir):
            for file in os.listdir(uploads_dir):
                if file.endswith('.xml'):
                    print(f"  - {uploads_dir}/{file}")
        else:
            print("  No uploads directory found") 