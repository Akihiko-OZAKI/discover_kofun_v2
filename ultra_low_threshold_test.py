#!/usr/bin/env python3
"""
è¶…ä½ä¿¡é ¼åº¦é–¾å€¤ã§ã®æ¨è«–ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import torch
import cv2
import numpy as np

def ultra_low_threshold_inference():
    """
    è¶…ä½ä¿¡é ¼åº¦é–¾å€¤ï¼ˆ0.01ï¼‰ã§æ¨è«–ã‚’å®Ÿè¡Œ
    """
    print("ğŸš€ Running ultra-low threshold inference (0.01)...")
    
    # YOLOv5ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    sys.path.insert(0, os.path.abspath('yolov5'))
    from yolov5.models.common import DetectMultiBackend
    from yolov5.utils.general import check_img_size, non_max_suppression, scale_boxes
    from yolov5.utils.torch_utils import select_device
    
    # è¨­å®š - è¶…ä½é–¾å€¤
    weights = 'yolov5/weights/best.pt'
    source = 'second_test_results/second_test.png'
    imgsz = (640, 640)
    conf_thres = 0.01  # è¶…ä½é–¾å€¤
    iou_thres = 0.45
    max_det = 1000
    device = select_device('')
    
    # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    model = DetectMultiBackend(weights, device=device)
    stride, names, pt = model.stride, model.names, model.pt
    imgsz = check_img_size(imgsz, s=stride)
    
    # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
    model.warmup(imgsz=(1 if pt else 1, 3, *imgsz))
    
    # ç”»åƒã®èª­ã¿è¾¼ã¿
    im0s = cv2.imread(source)
    if im0s is None:
        print(f"âŒ Could not read image: {source}")
        return
    
    # å‰å‡¦ç†
    im = cv2.resize(im0s, imgsz)
    im = im.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
    im = np.ascontiguousarray(im)
    im = torch.from_numpy(im).to(device)
    im = im.float()
    im /= 255
    if len(im.shape) == 3:
        im = im[None]
    
    # æ¨è«–
    pred = model(im, augment=False, visualize=False)
    
    # NMS
    pred = non_max_suppression(pred, conf_thres, iou_thres, classes=None, agnostic=False, max_det=max_det)
    
    # çµæœã®å‡¦ç†
    detections = []
    for i, det in enumerate(pred):
        if len(det):
            # åº§æ¨™ã‚’å…ƒã®ç”»åƒã‚µã‚¤ã‚ºã«ã‚¹ã‚±ãƒ¼ãƒ«
            det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0s.shape).round()
            
            # æ¤œå‡ºçµæœã‚’ä¿å­˜
            for *xyxy, conf, cls in reversed(det):
                detection = {
                    'bbox': [int(x) for x in xyxy],
                    'confidence': float(conf),
                    'class_id': int(cls),
                    'class_name': names[int(cls)] if int(cls) < len(names) else 'unknown'
                }
                detections.append(detection)
    
    # çµæœã®è¡¨ç¤º
    print(f"\nğŸ¯ Ultra-Low Threshold Results (conf_thres=0.01):")
    print(f"ğŸ“Š Total detections: {len(detections)}")
    
    if detections:
        print("âœ… DETECTIONS FOUND!")
        for i, det in enumerate(detections):
            print(f"   Detection #{i+1}:")
            print(f"     Class: {det['class_name']}")
            print(f"     Confidence: {det['confidence']:.4f}")
            print(f"     BBox: {det['bbox']}")
    else:
        print("âŒ Still no detections even with ultra-low threshold")
        print("ğŸ’¡ This might indicate:")
        print("   1. The model needs retraining")
        print("   2. The image doesn't contain kofun")
        print("   3. Model compatibility issues")
    
    return detections

if __name__ == "__main__":
    if not os.path.exists('second_test_results/second_test.png'):
        print("âŒ Please run test_second_xml.py first")
    else:
        detections = ultra_low_threshold_inference()
        
        if detections:
            print("\nğŸ‰ SUCCESS! Detections found with ultra-low threshold!")
            print("This confirms the system is working, but the model might need adjustment.")
        else:
            print("\nâš ï¸  No detections even with ultra-low threshold.")
            print("Consider testing with known positive samples or model retraining.") 