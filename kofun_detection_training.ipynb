
# å¤å¢³æ¤œå‡ºãƒ¢ãƒ‡ãƒ«å­¦ç¿’ - Google Colabç‰ˆ
# ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’Google Colabã§å®Ÿè¡Œã—ã¦ãã ã•ã„

# 1. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
!pip install torch torchvision
!pip install ultralytics
!pip install opencv-python
!pip install pandas
!pip install matplotlib
!pip install tqdm
!pip install requests
!pip install selenium

# 2. YOLOv5ã®ã‚¯ãƒ­ãƒ¼ãƒ³
!git clone https://github.com/ultralytics/yolov5
%cd yolov5
!pip install -r requirements.txt

# 3. ãƒ‡ãƒ¼ã‚¿åé›†ã¨å­¦ç¿’ã®çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
import os
import requests
import zipfile
import json
import pandas as pd
from pathlib import Path
import time
import concurrent.futures
from tqdm import tqdm

# å¤å¢³åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
kofun_coordinates = [
    [1, 34.698046, 135.809032],
    [2, 34.697919, 135.804807],
    [3, 34.701343, 135.802867],
    # ... ä»–ã®åº§æ¨™ãƒ‡ãƒ¼ã‚¿
]

# å›½åœŸåœ°ç†é™¢ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã™ã‚‹é–¢æ•°
def collect_gsi_data(area_bounds, max_files=50):
    """å›½åœŸåœ°ç†é™¢ã‹ã‚‰DEMãƒ‡ãƒ¼ã‚¿ã‚’åé›†"""
    print(f"ğŸŒ åœ°åŸŸ {area_bounds} ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹...")
    
    # å®Ÿéš›ã®å®Ÿè£…ã§ã¯å›½åœŸåœ°ç†é™¢ã®APIã‚’ä½¿ç”¨
    # ã“ã“ã§ã¯ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    collected_data = []
    for i in range(max_files):
        collected_data.append({
            'id': f'DEM_{i:04d}',
            'coordinates': area_bounds,
            'status': 'collected'
        })
    
    print(f"âœ… {len(collected_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†")
    return collected_data

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆé–¢æ•°
def create_training_dataset(collected_data, kofun_coordinates):
    """å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
    print("ğŸ“Š å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆä¸­...")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs('dataset/images/train', exist_ok=True)
    os.makedirs('dataset/images/val', exist_ok=True)
    os.makedirs('dataset/labels/train', exist_ok=True)
    os.makedirs('dataset/labels/val', exist_ok=True)
    
    # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆ
    dataset_info = {
        'total_images': len(collected_data),
        'train_count': int(len(collected_data) * 0.8),
        'val_count': len(collected_data) - int(len(collected_data) * 0.8)
    }
    
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†: {dataset_info['total_images']}ä»¶")
    return dataset_info

# 4. ãƒ‡ãƒ¼ã‚¿åé›†ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã®å®Ÿè¡Œ
print("ğŸš€ ãƒ‡ãƒ¼ã‚¿åé›†ã¨å­¦ç¿’ã®çµ±åˆãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹")
print("=" * 50)

# æ—¥æœ¬ã®ä¸»è¦ãªå¤å¢³åœ°åŸŸ
areas = [
    (34.4, 35.0, 135.4, 136.0),  # å¤§é˜ªãƒ»å¥ˆè‰¯å‘¨è¾º
    (34.8, 35.2, 135.6, 135.9),  # äº¬éƒ½å‘¨è¾º
]

total_collected = 0
for area in areas:
    collected = collect_gsi_data(area, max_files=25)
    total_collected += len(collected)

print(f"ğŸ“Š ç·åé›†ãƒ‡ãƒ¼ã‚¿æ•°: {total_collected}ä»¶")

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
dataset_info = create_training_dataset(total_collected, kofun_coordinates)

# 5. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
dataset_config = """
# Dataset configuration
path: ./dataset  # dataset root dir
train: images/train  # train images (relative to 'path')
val: images/val  # val images (relative to 'path')

# Classes
nc: 1  # number of classes
names: ['kofun']  # class names
"""

with open('kofun_dataset.yaml', 'w') as f:
    f.write(dataset_config)

print("âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ")

# 6. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®å®Ÿè¡Œ
print("ğŸ¤– YOLOv5ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...")
!python train.py --img 640 --batch 16 --epochs 50 --data kofun_dataset.yaml --weights yolov5s.pt --cache

# 7. å­¦ç¿’çµæœã®ç¢ºèª
import matplotlib.pyplot as plt
from PIL import Image

print("ğŸ“ˆ å­¦ç¿’çµæœã‚’ç¢ºèªä¸­...")
try:
    # å­¦ç¿’æ›²ç·šã®è¡¨ç¤º
    results = Image.open('runs/train/exp/results.png')
    plt.figure(figsize=(12, 8))
    plt.imshow(results)
    plt.axis('off')
    plt.title('Training Results')
    plt.show()
except:
    print("å­¦ç¿’çµæœã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸ")

# 8. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
from google.colab import files
print("ğŸ’¾ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
try:
    files.download('runs/train/exp/weights/best.pt')
    files.download('runs/train/exp/weights/last.pt')
    print("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
except:
    print("âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")

print("ğŸ‰ ãƒ‡ãƒ¼ã‚¿åé›†ã‹ã‚‰å­¦ç¿’ã¾ã§å®Œäº†ï¼")
